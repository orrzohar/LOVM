{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipdb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pickle\n",
    "from modelGPT.utils import eval_on_dataset\n",
    "from modelGPT.model_gpt_predictor import ModelGPTPredictor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from modelGPT.constants import DATASET_COL, MODELS, PARAMETERS, FEATURE_ORDER_DICT, ALL_FEATURES, GROUND_TRUTH_CSV, MODEL_NAME_COL\n",
    "\n",
    "\n",
    "sns.set_palette('colorblind', n_colors=9)\n",
    "linestyle = ['-','--','-.', ':']\n",
    "#sns.set(font_scale=1.2)\n",
    "plt.rcParams['font.size'] = 13\n",
    "\n",
    "df = pd.read_csv(GROUND_TRUTH_CSV)\n",
    "all_dataset = df.dataset.unique()\n",
    "PRED_TARGET='acc1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19325a68-e390-4cf2-a3b2-74280aa297e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_order = {'imagenet1k':'ImageNet','sun397':'SUN397', 'flowers':'flowers102', 'caltech101':'CalTech101',\n",
    "              'pets':'Oxford Pets','cifar100':'CIFAR100', \n",
    "          'cars':'Stanford Cars','stl10':'stl10','voc2007':'VOC2007','resisc45':'resisc45',\n",
    "              'eurosat':'euroSAT','fgvc_aircraft':'FGVC aircraft', 'gtsrb':'GTSRB',\n",
    "          'kitti_closest_vehicle_distance':'KITTI','country211':'country211', 'dmlab':'DMLab', 'svhn':'SVHN','fer2013':'FER2013','diabetic_retinopathy':'Retinopathy',\n",
    "          'clevr_closest_object_distance':'CLEVR-DISTANCE','clevr_count_all':'CLEVR-COUNT','mnist':'MNIST','dtd':'DTD', 'pcam':'Pcam', 'renderedsst2':'renderedsst2'\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296918ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_rankings = {}\n",
    "\n",
    "all_dataset = df.dataset.unique()\n",
    "non_cls=['svhn','country211','mnist','clevr_closest_object_distance', 'clevr_count_all', 'eurosat', 'pcam',  'kitti_closest_vehicle_distance', 'fer2013', 'dtd', 'renderedsst2','diabetic_retinopathy','dmlab']\n",
    "real_cls = [i for i in all_dataset if i not in non_cls and i != 'imagenet1k']\n",
    "datasets = ['imagenet1k']+real_cls + non_cls\n",
    "\n",
    "order_dict = {v: i for i, v in enumerate(datasets)}\n",
    "\n",
    "df['dataset_order'] = pd.Categorical(df['dataset'], categories=order_dict.keys(), ordered=True).map(order_dict)\n",
    "\n",
    "# Sort the DataFrame by the 'datasets' column\n",
    "df = df.sort_values('dataset')\n",
    "models=df.model.unique()\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_dataset = df.loc[df.dataset==dataset][[\"model_fullname\", \"pretrained\", PRED_TARGET,\"dataset\", \"dataset_order\"]]\n",
    "    dataset_rankings[dataset] = df_dataset.sort_values(PRED_TARGET, ascending=False).reset_index()\n",
    "    dataset_rankings[dataset]['rank']=dataset_rankings[dataset].index\n",
    "\n",
    "    \n",
    "len(all_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = {\n",
    "    'coca_ViT-B-32 laion2b_s13b_b90k': 'CoCa-ViT-B/32, L2b-c',\n",
    "    'coca_ViT-B-32 mscoco_finetuned_laion2b_s13b_b90k': 'CoCa-ViT-B/32, L2b-c + coco',\n",
    "    'coca_ViT-L-14 laion2b_s13b_b90k': 'CoCa-ViT-L/14, L2b-c',\n",
    "    'coca_ViT-L-14 mscoco_finetuned_laion2b_s13b_b90k': 'CoCa-ViT-L/14, L2b-c + coco',\n",
    "    'convnext_base laion400m_s13b_b51k': 'ConvNEXT-B, L400m-c',\n",
    "    'convnext_base_w laion2b_s13b_b82k': 'ConvNEXT-BW, L2b-d',\n",
    "    'convnext_base_w laion2b_s13b_b82k_augreg': 'ConvNEXT-BW, L2b-e',\n",
    "    'convnext_base_w laion_aesthetic_s13b_b82k': 'ConvNEXT-BW, L2b-f',\n",
    "    'convnext_base_w_320 laion_aesthetic_s13b_b82k': 'ConvNEXT-BW-320, L2b-f',\n",
    "    'convnext_base_w_320 laion_aesthetic_s13b_b82k_augreg': 'ConvNEXT-B-BW-320, L2b-g',\n",
    "    'convnext_large_d laion2b_s26b_b102k_augreg': 'ConvNEXT-LD, L2b-h',\n",
    "    'convnext_large_d_320 laion2b_s29b_b131k_ft': 'ConvNEXT-LD-320, L2b-i',\n",
    "    'convnext_large_d_320 laion2b_s29b_b131k_ft_soup': 'ConvNEXT-LD-320, L2b-j',\n",
    "    'RN50 openai': 'RN50, WIT',\n",
    "    'RN101 openai': 'RN101, WIT',\n",
    "    'RN50x4 openai': 'RN50x4, WIT',\n",
    "    'RN50x16 openai': 'RN50x16, WIT',\n",
    "    'RN50x64 openai': 'RN50x64, WIT',\n",
    "    'ViT-B-32 openai': 'ViT-B/32, WIT',\n",
    "    'ViT-B-16 openai': 'ViT-B/16, WIT',\n",
    "    'ViT-L-14 openai': 'ViT-L/14, WIT',\n",
    "    'ViT-L-14-336 openai': 'ViT-L/14-336, WIT',\n",
    "    'ViT-B-16 laion400m_e32': 'ViT-B/16, L400m-a',\n",
    "    'ViT-B-16-plus-240 laion400m_e32': 'ViT-B/16-240, L400m-a',\n",
    "    'ViT-B-32 laion2b_e16': 'ViT-B/32, L2b-c',\n",
    "    'ViT-B-32 laion2b_s34b_b79k': 'ViT-B/32, L2b-b',\n",
    "    'ViT-B-32 laion400m_e31': 'ViT-B/32, L400m-b',\n",
    "    'ViT-B-32 laion400m_e32': 'ViT-B/32, L400m-a',\n",
    "    'ViT-B-32-quickgelu laion400m_e32': 'ViT-B/32, L400m-a',\n",
    "    'ViT-H-14 laion2b_s32b_b79k': 'ViT-H/14, L2b-b',\n",
    "    'ViT-L-14 laion2b_s32b_b82k': 'ViT-L/14, L2b-b',\n",
    "    'ViT-L-14 laion400m_e31': 'ViT-L/14, L400m-b',\n",
    "    'ViT-L-14 laion400m_e32': 'ViT-L/14, L400m-a',\n",
    "    'ViT-g-14 laion2b_s12b_b42k': 'ViT-G/14, L2b-a',\n",
    "    'ViT-g-14 laion2b_s34b_b88k': 'ViT-G/14, L2b-b'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0988c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots(figsize=(15, 6.5))\n",
    "\n",
    "\n",
    "new_names = df.model_fullname.unique()\n",
    "original_names = [name_mapping[name] for name in new_names]\n",
    "\n",
    "print(original_names)\n",
    "\n",
    "legend=[]\n",
    "tmp=pd.concat(dataset_rankings.values())\n",
    "model_names_=tmp.model_fullname.unique()\n",
    "for i, m in enumerate(model_names_):\n",
    "    tmptmp=tmp.loc[tmp.model_fullname==m].sort_values('dataset_order')\n",
    "    tmptmp = tmptmp.reset_index().drop_duplicates().set_index('index')\n",
    "    sns.lineplot(x=tmptmp['dataset'], y=tmptmp['rank']+1, ax=ax0, linestyle=linestyle[i//9], label=name_mapping[m])\n",
    "    \n",
    "\n",
    "\n",
    "gt_ranking=tmp\n",
    "ax0.invert_yaxis()\n",
    "ax0.set_xticklabels([name_order[d] for d in datasets], rotation=90)\n",
    "\n",
    "ax0.legend(loc=[1.01,-0.27], facecolor='white',ncol=1, labelspacing=0, fontsize =11)\n",
    "ax0.set_xlabel('Dataset')\n",
    "ax0.set_xlim([0,22])\n",
    "ax0.set_ylabel('Ground-Truth Ranking')\n",
    "ax0.set_yticks([i+1 for i in range(0,35, 4)])\n",
    "#ax0.set_ylim([15,0])\n",
    "plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "plt.savefig(\"RankingGT.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af53189",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['text-f1', 'IN-score']\n",
    "#features = ['superclass_metric', 'inter_close', 'IN-score']\n",
    "#target = PRED_TARGET\n",
    "df_dataset=df\n",
    "\n",
    "model_gpt = ModelGPTPredictor(df, features=features)\n",
    "pred, _ = model_gpt.loo_dataset_rank()\n",
    "pred = pred.T\n",
    "\n",
    "dataset_rankings={}\n",
    "for dataset in datasets:\n",
    "    df_dataset = df.loc[df.dataset==dataset][[\"model_fullname\", \"pretrained\", \"dataset\", \"dataset_order\"]]\n",
    "\n",
    "    for m_fn in df_dataset.model_fullname:\n",
    "        df_dataset.loc[df_dataset.model_fullname==m_fn, 'lin_model']= pred[dataset][m_fn]\n",
    "    \n",
    "    dataset_rankings[dataset] = df_dataset.sort_values(\"lin_model\", ascending=False).reset_index()\n",
    "    dataset_rankings[dataset]['rank']=dataset_rankings[dataset].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3aa550-b2d5-407f-8d8e-6069d88ae162",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots(figsize=(15, 6.5))\n",
    "\n",
    "\n",
    "new_names = df.model_fullname.unique()\n",
    "original_names = [name_mapping[name] for name in new_names]\n",
    "\n",
    "print(original_names)\n",
    "\n",
    "legend=[]\n",
    "tmp=pd.concat(dataset_rankings.values())\n",
    "\n",
    "for i, m in enumerate(model_names_):\n",
    "    tmptmp=tmp.loc[tmp.model_fullname==m].sort_values('dataset_order')\n",
    "    tmptmp = tmptmp.reset_index().drop_duplicates().set_index('index')\n",
    "    sns.lineplot(x=tmptmp['dataset'], y=tmptmp['rank']+1, ax=ax0, linestyle=linestyle[i//9], label=name_mapping[m])\n",
    "    \n",
    "\n",
    "\n",
    "gt_ranking=tmp\n",
    "ax0.invert_yaxis()\n",
    "ax0.set_xticklabels([name_order[d] for d in datasets], rotation=90)\n",
    "\n",
    "ax0.legend(loc=[1.01,-0.27], facecolor='white',ncol=1, labelspacing=0, fontsize =11)\n",
    "ax0.set_xlabel('Dataset')\n",
    "ax0.set_xlim([0,22])\n",
    "ax0.set_ylabel('Unified Ranking')\n",
    "ax0.set_yticks([i+1 for i in range(0,35, 4)])\n",
    "#ax0.set_ylim([15,0])\n",
    "plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "plt.savefig(\"RankingU.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LOVM.lovm import LOVM\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#FF5733', '#FFC300', '#DAF7A6', '#AED6F1', '#F1948A', '#AF7AC5', '#F8C471', '#D7DBDD', '#A2D9CE', '#5499C7', '#BB8FCE', '#F7DC6F', '#00CED1', '#FF6347', '#00FFFF']\n",
    "\n",
    "target = 'acc1'\n",
    "df_dataset=df\n",
    "\n",
    "lovm = LOVM()\n",
    "pred = lovm.get_imagenet_dataset_rank()\n",
    "pred = pred.T\n",
    "\n",
    "dataset_rankings={}\n",
    "for dataset in datasets:\n",
    "    df_dataset = df.loc[df.dataset==dataset][[\"model_fullname\", \"pretrained\", \"dataset\", \"dataset_order\"]]\n",
    "\n",
    "    for m_fn in df_dataset.model_fullname:\n",
    "        df_dataset.loc[df_dataset.model_fullname==m_fn, 'lin_model']= pred[dataset][m_fn]\n",
    "    \n",
    "    dataset_rankings[dataset] = df_dataset.sort_values(\"lin_model\", ascending=False).reset_index()\n",
    "    dataset_rankings[dataset]['rank']=dataset_rankings[dataset].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots(figsize=(15, 6.5))\n",
    "\n",
    "\n",
    "new_names = df.model_fullname.unique()\n",
    "original_names = [name_mapping[name] for name in new_names]\n",
    "\n",
    "print(original_names)\n",
    "\n",
    "legend=[]\n",
    "tmp=pd.concat(dataset_rankings.values())\n",
    "for i, m in enumerate(model_names_):\n",
    "    tmptmp=tmp.loc[tmp.model_fullname==m].sort_values('dataset_order')\n",
    "    tmptmp = tmptmp.reset_index().drop_duplicates().set_index('index')\n",
    "    sns.lineplot(x=tmptmp['dataset'], y=tmptmp['rank']+1, ax=ax0, linestyle=linestyle[i//9], label=name_mapping[m])\n",
    "    \n",
    "\n",
    "\n",
    "gt_ranking=tmp\n",
    "ax0.invert_yaxis()\n",
    "ax0.set_xticklabels([name_order[d] for d in datasets], rotation=90)\n",
    "\n",
    "ax0.legend(loc=[1.01,-0.27], facecolor='white',ncol=1, labelspacing=0, fontsize =11)\n",
    "ax0.set_xlabel('Dataset')\n",
    "ax0.set_xlim([0,22])\n",
    "ax0.set_ylabel('INB-Ranking')\n",
    "ax0.set_yticks([i+1 for i in range(0,35, 4)])\n",
    "#ax0.set_ylim([15,0])\n",
    "plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "plt.savefig(\"RankingINB.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410f510-5c96-49e0-80b2-2fe8ccd2e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelGPT.utils import eval_on_dataset\n",
    "sigmas = [0.00, 0.075, 0.1, 0.125, 0.2, 0.4]\n",
    "\n",
    "for dataset in datasets:\n",
    "    data ={}\n",
    "    with open(f\"modelGPT/encoded_captions_dataset/{dataset}.pkl\", 'rb') as file:\n",
    "        while True:\n",
    "            try:\n",
    "                loaded_object = pickle.load(file)\n",
    "                data.update(loaded_object)\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    models = {}\n",
    "    with open(f\"modelGPT/models/{dataset}.pkl\", 'rb') as file:\n",
    "        while True:\n",
    "            try:\n",
    "                loaded_object = pickle.load(file)\n",
    "                models.update(loaded_object)\n",
    "            except EOFError:\n",
    "                break\n",
    "            \n",
    "    for sigma in tqdm(sigmas, leave=False, position=0, desc=dataset):\n",
    "        for m in models.keys():\n",
    "            tmp=eval_on_dataset(data[m], models[m].cuda(), sigma)\n",
    "            df.loc[(df.model_fullname==m[0]+\" \"+m[1])&(df.dataset==dataset), f'text-acc1-{sigma}']=tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada0240-cb81-41d2-ab13-fd1fb0965a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "fig, ax = plt.subplots(2, 3,figsize=(15, 8))\n",
    "colors  = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#FF5733', '#FFC300', '#DAF7A6', '#AED6F1', '#F1948A', '#AF7AC5', '#F8C471', '#D7DBDD', '#A2D9CE', '#5499C7', '#BB8FCE', '#F7DC6F', '#00CED1', '#FF6347', '#00FFFF']\n",
    "y_true  = []\n",
    "y_preds = []\n",
    "legend  = []\n",
    "sigmas = [0.00, 0.075, 0.1, 0.125, 0.2, 0.4]\n",
    "for j, sigma in enumerate(sigmas):\n",
    "    row, col = np.unravel_index(j, (2, 3))\n",
    "    for i, dataset in enumerate(df.dataset.unique()):\n",
    "        tmp = df.loc[df.dataset==dataset]\n",
    "        ax[row, col].plot( tmp[PRED_TARGET],tmp[f'text-acc1-{sigma}'],'*', c=colors[i])\n",
    "        score = round(pearsonr(tmp[PRED_TARGET], tmp[f'text-acc1-{sigma}']).statistic, 3)\n",
    "        l1 = round(mean_absolute_error(tmp[PRED_TARGET], tmp[f'text-acc1-{sigma}']),3)\n",
    "        r2 = round(r2_score(tmp[PRED_TARGET], tmp[f'text-acc1-{sigma}']),3)\n",
    "\n",
    "        ax[row, col].set_title(f'$\\sigma$ = {sigma}, $R_2$={r2}')\n",
    "        ax[row, col].set_xlim([0.0,1.0])\n",
    "        ax[row, col].set_ylim([0.0,1.0])\n",
    "        \n",
    "        ax[row, col].set_ylabel('Text Top-1 Accuracy')\n",
    "        ax[row, col].set_xlabel('Ground-Truth Top-1 Accuracy')\n",
    "        #y_true.extend(y)\n",
    "        #y_preds.extend(y_pred)\n",
    "        \n",
    "ax[row, col].legend([name_order[f] for f in df.dataset.unique()], loc=(1.05,0.0))\n",
    "\n",
    "for j, _ in enumerate(sigmas):\n",
    "    row, col = np.unravel_index(j, (2, 3))\n",
    "    ax[row, col].plot([0,1],[0,1], c='k')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.35)\n",
    "plt.savefig(\"TextAccurcayExperiment.png\", dpi=300)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
